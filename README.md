# Mini_Personal_Assistant
HAND GESTURE RECOGNITION AND VOICE COMMAND CONTROL
This repository hosts a Python-based project that enables real-time hand gesture recognition and voice command control. The system utilizes various libraries including OpenCV, Mediapipe, TensorFlow, Keras, and SpeechRecognition to provide users with an interactive means of controlling system commands via hand gestures and voice commands using a webcam and microphone.

REQUIREMENTS
This project requires specific versions of several libraries:
Python
OpenCV
Mediapipe
TensorFlow
Keras
SpeechRecognition
numpy
pyautogui

USAGE
Activate Gesture Mode by saying "Activate Hand Gesture." Deactivate Gesture Mode by saying "Deactivate Hand Gesture." The system recognizes predefined hand gestures to execute system commands as defined in the code. Additionally, voice commands for various system operations are available (refer to the code for the complete list of available commands).

ADDITIONAL NOTES
The code uses a pre-trained model for hand gesture recognition, and it's essential to have the model file present in the specified directory. Ensure a functional webcam and microphone to enable gesture and voice recognition functionalities. Customization of system commands can be done by modifying the code based on specific requirements or preferences.
